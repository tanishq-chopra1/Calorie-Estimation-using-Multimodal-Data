# ğŸ½ï¸ Calorie Estimation using Multimodal Data

This project is a deep learning system that estimates the **calories in a meal** using **multimodal inputs**:

- ğŸ–¼ï¸ Food Image
- ğŸ“Š Continuous Glucose Monitoring (CGM) Data
- ğŸ§ Demographic Information (e.g., age, gender)

The model combines computer vision, time-series, and tabular data into a single architecture to predict calorie content in real-time.

---

## ğŸš€ Project Overview

Traditional calorie estimation apps rely solely on image classification. This project improves prediction by combining three data sources:

- **CNN** extracts features from the food image.
- **BiDirectional-LSTM** processes CGM time-series data.
- **MLP** handles demographic inputs.
- The outputs are fused and passed through dense layers for final calorie prediction.

## Architecture
![Architecture](Architecture.png)

---

## ğŸ“¦ Requirements

Install dependencies:

Make sure your Python version is 3.8+ and that you have:

- PyTorch
- torchvision
- pandas
- numpy
- matplotlib
- pillow
- scikit-learn

---

## ğŸ§  Key Features

- âœ… Real-world CGM + image fusion
- âœ… Modular architecture (easy to plug in other modalities)
- âœ… Lightweight and fast for prototyping

---

## ğŸ“Š Results

- Achieved **0.26 RMRSE** compared to image-only models.
- Demonstrated robustness to noisy glucose data.

---

## ğŸ“š Future Work

- Add mobile-friendly inference API
- Expand dataset with annotated food images
- Incorporate BMI and activity level for richer predictions
